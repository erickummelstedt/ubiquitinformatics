{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defining_JSON_multimers(max_multimer_length):\n",
    "\n",
    "    # set up list to hold the json_dicts and contexts\n",
    "    multimer_dicts = []\n",
    "    \n",
    "    acceptor, context = iterate_through_ubiquitin(histag_ubi_ubq_1)\n",
    "    multimer_dicts.append({\n",
    "        'multimers': [acceptor],\n",
    "        'contexts': [context]\n",
    "        })\n",
    "    \n",
    "    \n",
    "    for i in range(2, max_multimer_length+1):\n",
    "        logging.info(f\"Building {i}-mers\")\n",
    "        \n",
    "        # adaptable list that new things get added to\n",
    "        json_dict_list_temp = []\n",
    "        free_lysines_list_temp = []\n",
    "\n",
    "        # loop through the multimer_dicts\n",
    "        for current_index, multimer_dict in enumerate(multimer_dicts):\n",
    "            json_dict_list = multimer_dict['multimers']\n",
    "            free_lysines_list = multimer_dict['contexts']\n",
    "\n",
    "            for current_json_dict, free_lysines in zip(json_dict_list, free_lysines_list):\n",
    "                for chain_number, lys in free_lysines:\n",
    "                    new_json_dict = ubiquitin_building(current_json_dict, ubi_ubq_1, chain_number, lys)\n",
    "\n",
    "                    json_dict, free_lysines = find_free_lysines(new_json_dict)\n",
    "                    \n",
    "                    # append free lysines and json_dict to lists\n",
    "                    json_dict_list_temp.append(json_dict)\n",
    "                    free_lysines_list_temp.append(free_lysines)\n",
    "\n",
    "        ## delete duplicates\n",
    "        json_dict_list_temp, free_lysines_list_temp = delete_duplicate_jsons_free_lysines(json_dict_list_temp, free_lysines_list_temp)\n",
    "\n",
    "        ## copy_lists\n",
    "        multimer_dicts.append({\n",
    "            'multimers': json_dict_list_temp.copy(),\n",
    "            'contexts': free_lysines_list_temp.copy()\n",
    "            })\n",
    "        json_dict_df = pd.DataFrame([json_dict_list_temp])\n",
    "        json_dict_df.to_csv(f\".data/multimers/{i}mers.csv\", index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # from test_data import histag_ubi_ubq_1, ubi_ubq_1\n",
    "    histag_ubi_ubq_1\n",
    "    ubi_ubq_1\n",
    "\n",
    "    # run itereate through ubiquitin to get context\n",
    "    # pull the free lysines from the context\n",
    "\n",
    "    # ubiquitin_build on each lysine with ubi_ubq_1\n",
    "\n",
    "    # run iterate through ubiquitin to get context\n",
    "    \n",
    "    # add the new json_dict & context to a dictionary\n",
    "    \n",
    "    # delete duplciates from the dictionary\n",
    "\n",
    "\n",
    "    #new_dict = json_dict_list[0]\n",
    "    #\n",
    "    #for chain_number, lys in free_lysines_list[0]:\n",
    "    #    new_json_dict = ubiquitin_building(new_dict, ubi_ubq_1, chain_number, lys)\n",
    "    #\n",
    "    for i in range(2, max_multimer_length+1):\n",
    "        logging.info(i)\n",
    "        \n",
    "        # adaptable list that new things get added to\n",
    "        json_dict_list_temp = []\n",
    "        free_lysines_list_temp = []\n",
    "\n",
    "        # loop through json_dict_list\n",
    "        # use enumerate... \n",
    "        for current_index, loop_dict in enumerate(json_dict_list): \n",
    "            \n",
    "            for chain_number, lys in free_lysines_list[current_index]:\n",
    "                \n",
    "                new_json_dict = ubiquitin_building(loop_dict, ubi_ubq_1, chain_number, lys)\n",
    "\n",
    "                json_dict, free_lysines = find_free_lysines(new_json_dict)\n",
    "                \n",
    "                # append free lysines and json_dict to lists\n",
    "                json_dict_list_temp.append(json_dict)\n",
    "                free_lysines_list_temp.append(free_lysines)\n",
    "\n",
    "        ## delete duplicates\n",
    "        json_dict_list_temp, free_lysines_list_temp = delete_duplicate_jsons_free_lysines(json_dict_list_temp, free_lysines_list_temp)\n",
    "\n",
    "        ## copy_lists\n",
    "        json_dict_list = json_dict_list_temp.copy()\n",
    "        free_lysines_list = free_lysines_list_temp.copy()\n",
    "        json_dict_df = pd.DataFrame([json_dict_list])\n",
    "        json_dict_df.to_csv(\".data/multimers/\" + str(i) + 'mers.csv', index=False)\n",
    "        del(json_dict_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
