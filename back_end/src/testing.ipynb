{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f33d7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Handle paths for Jupyter (where __file__ is not defined)\n",
    "try:\n",
    "    current_path = Path(__file__).resolve()\n",
    "except NameError:\n",
    "    # __file__ is not defined in Jupyter; use cwd as fallback\n",
    "    current_path = Path.cwd()\n",
    "\n",
    "# Set up project paths\n",
    "project_root = current_path.parents[1] if len(current_path.parents) >= 3 else current_path\n",
    "local_path = project_root / 'back_end'\n",
    "\n",
    "# Add project paths to sys.path if not already present\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "if str(local_path) not in sys.path:\n",
    "    sys.path.insert(0, str(local_path))\n",
    "\n",
    "# Import project modules (will work if path is correct)\n",
    "import src.utils.utils\n",
    "import src.utils.logging_utils\n",
    "import src.main as main\n",
    "from src.plotting import *\n",
    "import src.data_cleaning as data_cleaning\n",
    "\n",
    "multimer_size = 5\n",
    "\n",
    "# Function to load data\n",
    "def download_data_dict(multimer_size):\n",
    "    input_dir = project_root / 'back_end' / 'data' / 'filtered_reaction_database' / f'multimer_size_{multimer_size}'\n",
    "    combined_database = pd.read_csv(input_dir / 'combined_database.csv', index_col=0)\n",
    "    context_history = pd.read_csv(input_dir / 'context_history.csv', index_col=0)\n",
    "    donor_history = pd.read_csv(input_dir / 'donor_history.csv', index_col=0)\n",
    "    reaction_history = pd.read_csv(input_dir / 'reaction_history.csv', index_col=0)\n",
    "    ubiquitin_history = pd.read_csv(input_dir / 'ubiquitin_history.csv', index_col=0)\n",
    "    return {\n",
    "        'combined_database': combined_database,\n",
    "        'context_history': context_history,\n",
    "        'donor_history': donor_history,\n",
    "        'reaction_history': reaction_history,\n",
    "        'ubiquitin_history': ubiquitin_history\n",
    "    }\n",
    "\n",
    "# Load the data\n",
    "data_dict = download_data_dict(multimer_size)\n",
    "combined_database = data_dict['combined_database']\n",
    "context_history = data_dict['context_history']\n",
    "donor_history = data_dict['donor_history']\n",
    "reaction_history = data_dict['reaction_history']\n",
    "ubiquitin_history = data_dict['ubiquitin_history']\n",
    "\n",
    "# Function to load data\n",
    "def download__all_data_dict(multimer_size):\n",
    "    input_dir = project_root / 'back_end' / 'data' / 'reaction_database' / f'multimer_size_{multimer_size}'\n",
    "    context_history = pd.read_csv(input_dir / 'context_history.csv', index_col=0)\n",
    "    donor_history = pd.read_csv(input_dir / 'donor_history.csv', index_col=0)\n",
    "    reaction_history = pd.read_csv(input_dir / 'reaction_history.csv', index_col=0)\n",
    "    ubiquitin_history = pd.read_csv(input_dir / 'ubiquitin_history.csv', index_col=0)\n",
    "    return {\n",
    "        'context_history': context_history,\n",
    "        'donor_history': donor_history,\n",
    "        'reaction_history': reaction_history,\n",
    "        'ubiquitin_history': ubiquitin_history\n",
    "    }\n",
    "\n",
    "# Load the data\n",
    "data_dict = download__all_data_dict(multimer_size)\n",
    "all_context_history = data_dict['context_history']\n",
    "all_donor_history = data_dict['donor_history']\n",
    "all_reaction_history = data_dict['reaction_history']\n",
    "all_ubiquitin_history = data_dict['ubiquitin_history']\n",
    "\n",
    "import json\n",
    "\n",
    "# Replace with the actual path to your file\n",
    "file_path = f\"/Users/ekummelstedt/le_code_base/ubiquitinformatics/front_end/src/data/multimer_id_to_json{multimer_size}.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    multimers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d83d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index if needed\n",
    "all_ubiquitin_history = all_ubiquitin_history.reset_index()\n",
    "all_context_history = all_context_history.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49e3044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be a separate function in run_file.pyxs\n",
    "multimered_ubiquitin_history, multimered_context_history = data_cleaning.global_deprotection_dual(all_ubiquitin_history, all_context_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b82d23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multimer_edges_by_lysines(context_data: dict, \n",
    "                                  lysine_ids: dict\n",
    "                                  ) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts edges from the context data where the source or target lysine ID is in the specified set.\n",
    "    \n",
    "    Parameters:\n",
    "        context_data (dict): Dictionary containing multimer contexts.\n",
    "        lysine_ids (set): Set of lysine IDs to filter edges by.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with keys as multimer IDs and values as lists of edges matching the lysine IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # DONE reveal all the edges for trimers \n",
    "    def reveal_edges(context_):\n",
    "        \"\"\"\n",
    "        Gives the ID of the linkages from the context.\n",
    "        \"\"\"\n",
    "        edges = context_['conjugated_lysines']\n",
    "        return edges\n",
    "\n",
    "    reveal_all_edges = {key: reveal_edges(value) for key, value in context_data.items()}\n",
    "\n",
    "    # DONE only select edges with K63 and K48 linkages\n",
    "    # Keep only entries where all edge labels are either K63 or K48\n",
    "    def filter_edges_by_labels(reveal_all_edges, labels=lysine_ids):\n",
    "        \"\"\"\n",
    "        Filters the edges in the reveal_all_edges dictionary to keep only those\n",
    "        where all edge labels are in the specified set of labels.\n",
    "        \n",
    "        Parameters:\n",
    "            reveal_all_edges (dict): Dictionary containing edges with their labels.\n",
    "            labels (set): Set of labels to filter by (default is {'K63', 'K48'}).\n",
    "        \n",
    "        Returns:\n",
    "            dict: Filtered dictionary with edges that match the criteria.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            key: edges\n",
    "            for key, edges in reveal_all_edges.items()\n",
    "            if all(edge[1] in labels for edge in edges)\n",
    "        } \n",
    "\n",
    "    return filter_edges_by_labels(reveal_all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c0af8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ub4_1': {32: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K48', 2], [2, 'K48', 3], [3, 'K48', 4]]\"},\n",
       " 'Ub4_2': {12: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K48', 2], [2, 'K48', 3], [3, 'K63', 4]]\"},\n",
       " 'Ub4_3': {40: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K48', 2], [2, 'K63', 3], [2, 'K48', 4]]\"},\n",
       " 'Ub4_4': {64: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [1, 'K48', 3], [3, 'K48', 4]]\"},\n",
       " 'Ub4_5': {16: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K48', 2], [2, 'K63', 3], [3, 'K48', 4]]\"},\n",
       " 'Ub4_6': {24: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K48', 2], [2, 'K63', 3], [3, 'K63', 4]]\"},\n",
       " 'Ub4_7': {36: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [1, 'K48', 3], [3, 'K63', 4]]\"},\n",
       " 'Ub4_8': {36: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K48', 3], [1, 'K48', 4]]\"},\n",
       " 'Ub4_9': {64: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K63', 3], [1, 'K48', 4]]\"},\n",
       " 'Ub4_10': {24: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K48', 3], [3, 'K48', 4]]\"},\n",
       " 'Ub4_11': {16: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K48', 3], [3, 'K63', 4]]\"},\n",
       " 'Ub4_12': {40: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K63', 3], [2, 'K48', 4]]\"},\n",
       " 'Ub4_13': {12: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K63', 3], [3, 'K48', 4]]\"},\n",
       " 'Ub4_14': {32: 'num_of_reactions',\n",
       "  'ubiDAG_edges': \"[[1, 'K63', 2], [2, 'K63', 3], [3, 'K63', 4]]\"}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DONE reveal all the edges for trimers \n",
    "def reveal_edges(context_):\n",
    "    \"\"\"\n",
    "    Gives the ID of the linkages from the context.\n",
    "    \"\"\"\n",
    "    edges = context_['conjugated_lysines']\n",
    "    return edges\n",
    "\n",
    "json_counting = {}\n",
    "\n",
    "for i in range(len(multimers.keys())):\n",
    "    num_of_reactions = len(multimered_ubiquitin_history[multimered_ubiquitin_history['final_multimer'] == multimers[f'Ub{multimer_size}_{i+1}']])\n",
    "    ubi_DAG, ubi_context = main.iterate_through_ubiquitin(multimers[f'Ub{multimer_size}_{i+1}'])\n",
    "    json_counting[f'Ub{multimer_size}_{i+1}'] = {\n",
    "        num_of_reactions: 'num_of_reactions', \n",
    "        'ubiDAG_edges': str(reveal_edges(ubi_context))\n",
    "        }\n",
    "json_counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cefd3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to amount of branching/graph isomorphism "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
